{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from internal_methods import createShiftSequence, pitchAugmentation, volumeAugmentation, noiseAugmentation\n",
    "import soundfile as sf\n",
    "from soundfile import write  # Assuming you have soundfile installed\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir: str = \"DataGathering\"\n",
    "raw_wake: str = \"DataGathering/wake\"\n",
    "raw_talk:str = \"DataGathering/background/my_talk\"\n",
    "raw_back:str = \"DataGathering/background/back\"\n",
    "# raw_background_dir: str = \"\"\n",
    "\n",
    "background_talk_dataset = \"\"  # create iterator and trimmer at the same time\n",
    "\n",
    "\n",
    "wake_augmented: str = \"DataGathering/augmented/wake\"\n",
    "back_augmented: str = \"DataGathering/augmented/background/back\"\n",
    "talk_augmented: str = \"DataGathering/augmented/background/my_talk\"\n",
    "\n",
    "urban_audio: str = \"urban_audio\"\n",
    "\n",
    "wake_train: str = \"data/wake\"\n",
    "back_train: str = \"data/background\"\n",
    "\n",
    "\n",
    "sr: int = 44100\n",
    "seconds: int = 2\n",
    "\n",
    "os.makedirs(main_dir, exist_ok=True)\n",
    "os.makedirs(raw_wake, exist_ok=True)\n",
    "os.makedirs(os.path.join(main_dir, \"background\"), exist_ok=True)\n",
    "os.makedirs(raw_talk, exist_ok=True)\n",
    "os.makedirs(raw_back, exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(main_dir, \"augmented\"), exist_ok=True)\n",
    "os.makedirs(wake_augmented, exist_ok=True)\n",
    "os.makedirs(os.path.join(main_dir, \"augmented\", \"background\"), exist_ok=True)\n",
    "os.makedirs(back_augmented, exist_ok=True)\n",
    "os.makedirs(talk_augmented, exist_ok=True)\n",
    "\n",
    "os.makedirs(urban_audio, exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(wake_train, exist_ok=True)\n",
    "os.makedirs(back_train, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume shifts small:  [0.8 1.2 1.6 2. ]\n",
      "Volume shifts:  [0.8 1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8]\n",
      "Pitch shifts small:  [-1.5 -1.  -0.5  0.   0.5  1.   1.5]\n",
      "Pitch shifts:  [-1.6 -1.4 -1.2 -1.  -0.8 -0.6 -0.4 -0.2 -0.   0.2  0.4  0.6  0.8  1.\n",
      "  1.2  1.4]\n",
      "Noise Shifts\n"
     ]
    }
   ],
   "source": [
    "# for background\n",
    "pitch_shifts_small = createShiftSequence(start=-1.5, stop=1.6, step=0.5)\n",
    "volume_shifts_small = createShiftSequence(start=0.8, stop=2.1, step=0.4)\n",
    "\n",
    "# for wake_word\n",
    "pitch_shifts = createShiftSequence(start=-1.6, stop=1.6, step=0.2)\n",
    "volume_shifts = createShiftSequence(start=0.8, stop=3, step=0.2)\n",
    "\n",
    "\n",
    "noise_shifts = [0.0008, 0.0005, 0.0002]\n",
    "\n",
    "\n",
    "print(\"Volume shifts small: \", volume_shifts_small)\n",
    "print(\"Volume shifts: \", volume_shifts)\n",
    "\n",
    "print(\"Pitch shifts small: \", pitch_shifts_small)\n",
    "print(\"Pitch shifts: \", pitch_shifts)\n",
    "\n",
    "print(\"Noise Shifts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wake-word Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumeAugmentation(input_directory=raw_wake,output_directory=wake_augmented, volume_shifts=volume_shifts, sr=sr)\n",
    "noiseAugmentation(input_directory=wake_augmented,output_directory=wake_augmented, noise_factors=noise_shifts, sr=sr)\n",
    "pitchAugmentation(input_directory=wake_augmented,output_directory=wake_augmented, pitch_shifts=pitch_shifts, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Background Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background\n",
    "volumeAugmentation(input_directory=raw_back,output_directory=back_augmented, volume_shifts=volume_shifts, sr=sr)\n",
    "noiseAugmentation(input_directory=back_augmented,output_directory=back_augmented, noise_factors=noise_shifts, sr=sr)\n",
    "pitchAugmentation(input_directory=back_augmented,output_directory=back_augmented, pitch_shifts=pitch_shifts_small, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# background talk\n",
    "volumeAugmentation(input_directory=raw_talk,output_directory=talk_augmented, volume_shifts=volume_shifts_small, sr=sr)\n",
    "noiseAugmentation(input_directory=talk_augmented,output_directory=talk_augmented, noise_factors=noise_shifts, sr=sr)\n",
    "pitchAugmentation(input_directory=talk_augmented,output_directory=talk_augmented, pitch_shifts=pitch_shifts_small, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Urban Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processsUrbanData(\n",
    "    dataset_path: str = \"urban-dataset\",\n",
    "    output_directory: str = \"urban_audio\",\n",
    "    n_samples: int = 100,\n",
    "):\n",
    "    def list_subfolders(directory):\n",
    "        subfolders = [f.path for f in os.scandir(directory) if f.is_dir()]\n",
    "\n",
    "        return subfolders\n",
    "\n",
    "    def split_audio_by_length(\n",
    "        audio_path: str,\n",
    "        output_directory: str,\n",
    "        segment_duration: int = 2,\n",
    "        sr: int = 44100,\n",
    "        segment_counter: int | None = None,\n",
    "        n_samples: int | None = None,\n",
    "    ):\n",
    "\n",
    "        if segment_counter is None:\n",
    "            segment_counter = 0\n",
    "\n",
    "        # Load audio data\n",
    "        y, _ = librosa.load(audio_path, sr=sr)  # Load without specifying sample rate\n",
    "\n",
    "        # Check audio duration\n",
    "        duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        if duration < segment_duration:\n",
    "            return segment_counter\n",
    "\n",
    "        # Determine number of segments\n",
    "        num_segments = int(duration / segment_duration)\n",
    "\n",
    "        # Split audio into segments\n",
    "        segment_length = int(\n",
    "            sr * segment_duration\n",
    "        )  # Convert segment duration to samples\n",
    "\n",
    "        for sequence_idx in range(num_segments):\n",
    "            start = sequence_idx * segment_length\n",
    "            end = start + segment_length\n",
    "            segment = y[start:end]\n",
    "\n",
    "            # Create output filename\n",
    "            file_name, file_ext = os.path.splitext(os.path.basename(audio_path))\n",
    "            output_file = f\"urban_segment_{segment_counter}{file_ext}\"\n",
    "            output_path = os.path.join(output_directory, output_file)\n",
    "\n",
    "            # Stop iteration when sample count is enough\n",
    "            if segment_counter == n_samples:\n",
    "                return -1\n",
    "\n",
    "            # Update the number of made segments\n",
    "            segment_counter += 1\n",
    "            # Save segment\n",
    "            write(output_path, segment, sr)\n",
    "\n",
    "        return segment_counter\n",
    "\n",
    "    subfolders = list_subfolders(dataset_path)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    segment_counter = 0\n",
    "\n",
    "    for folder in subfolders:\n",
    "        # Iterate through each subfolder\n",
    "        for audio_file in os.scandir(folder):\n",
    "            # Iterate through each audio file in the subfolder\n",
    "\n",
    "            # Get the path of the audio file\n",
    "            audio_path = audio_file.path\n",
    "\n",
    "            segment_counter = split_audio_by_length(\n",
    "                audio_path=audio_path,\n",
    "                output_directory=output_directory,\n",
    "                segment_duration=seconds,\n",
    "                sr=sr,\n",
    "                segment_counter=segment_counter,\n",
    "                n_samples=n_samples,\n",
    "            )\n",
    "            if segment_counter == -1:\n",
    "                return\n",
    "\n",
    "\n",
    "processsUrbanData(dataset_path=\"urban-dataset\", output_directory=\"urban_audio\", n_samples=urban_sample_count)\n",
    "\n",
    "urban_sample_count = len(os.listdir(\"urban_audio\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_each = len(os.listdir(wake_train)) # n_samples background (talk+back +urban) and n_samples wake word\n",
    "n_samples_each = n_samples_each // 3 * 3  # ensure equal number of samples\n",
    "\n",
    "talk_sample_count = back_sample_count = (n_samples_each - urban_sample_count) //2\n",
    "\n",
    "n_samples_each, sum((talk_sample_count, back_sample_count, urban_sample_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble all the files into data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_directory(\n",
    "    source_dir, destination_dir, n_samples: int | None = None, use_shuffle=True\n",
    "):\n",
    "\n",
    "    # List files in the source directory\n",
    "    files = os.listdir(source_dir)\n",
    "    if use_shuffle:\n",
    "        random.shuffle(files)\n",
    "\n",
    "    if n_samples is not None:\n",
    "        files = files[:n_samples]\n",
    "\n",
    "    # Copy each file from the source directory to the destination directory\n",
    "    for file in files:\n",
    "        source_file = os.path.join(source_dir, file)\n",
    "        destination_file = os.path.join(destination_dir, file)\n",
    "        shutil.move(source_file, destination_file)\n",
    "        \n",
    "        \n",
    "\n",
    "move_to_directory(source_dir=wake_augmented, destination_dir=wake_train, n_samples=n_samples_each)\n",
    "move_to_directory(source_dir=urban_audio, destination_dir=back_train, n_samples=urban_sample_count)\n",
    "move_to_directory(source_dir=back_augmented, destination_dir=back_train, n_samples=back_sample_count)\n",
    "move_to_directory(source_dir=talk_augmented, destination_dir=back_train, n_samples=talk_sample_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Audio shape: {audio.shape}\")\n",
    "# print(f\"Spectrogram shape: {spectrogram.shape}\")\n",
    "# print(f\"Normalized spectrogram shape: {normalized_spectrogram.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
