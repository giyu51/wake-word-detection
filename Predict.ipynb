{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyaudio\n",
    "# import numpy as np\n",
    "# from collections import deque\n",
    "# import soundfile as sf\n",
    "# import tensorflow as tf\n",
    "# import time\n",
    "# from internal_methods import spectrogramFromAudioData\n",
    "\n",
    "# from threading import Thread\n",
    "# from queue import Queue\n",
    "\n",
    "\n",
    "# class AudioProcessor:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         sample_shape=(40, 173),\n",
    "#         batch_size=32,\n",
    "#         rate=44100,\n",
    "#         channels=1,\n",
    "#         format=pyaudio.paFloat32,\n",
    "#         duration=2,\n",
    "#         model_name: str = \"model.keras\",\n",
    "#         use_model_warm_up=True,\n",
    "#     ):\n",
    "#         self.RATE = rate\n",
    "#         self.CHANNELS = channels\n",
    "#         self.FORMAT = format\n",
    "#         self.SAMPLE_WIDTH = pyaudio.PyAudio().get_sample_size(format)\n",
    "#         self.DURATION = duration\n",
    "#         self.CHUNK = self.RATE  # 1 second chunks\n",
    "#         self.audio_buffer = deque(maxlen=self.DURATION)\n",
    "\n",
    "#         self.saving_counter = 0\n",
    "\n",
    "#         self.sample_shape = sample_shape\n",
    "#         self.batch_size = batch_size\n",
    "#         self.batch_placeholder = np.zeros(\n",
    "#             shape=(self.batch_size - 1,) + self.sample_shape\n",
    "#         )  # Example placeholder\n",
    "#         self.model_name = model_name\n",
    "#         self._model = self.load_model()  # Placeholder for loading your model\n",
    "\n",
    "            \n",
    "#         self.queue = Queue()\n",
    "#         self.processing_thread = Thread(target=self.process_audio)\n",
    "#         self.processing_thread.daemon = True\n",
    "#         self.processing_thread.start()\n",
    "\n",
    "#         if use_model_warm_up:\n",
    "#             self.warm_up_model()\n",
    "    \n",
    "    \n",
    "#     def load_model(self):\n",
    "#         return tf.keras.models.load_model(self.model_name)\n",
    "\n",
    "#     def warm_up_model(self, cycles: int = 5):\n",
    "#         print(\"Warming up the model...\")\n",
    "\n",
    "#         dummy_input = np.zeros(\n",
    "#             shape=(self.batch_size,) + self.sample_shape\n",
    "#         )  # Replace with appropriate shape\n",
    "#         for _ in range(cycles):\n",
    "#             self._model.predict(dummy_input, verbose=0)\n",
    "\n",
    "#         print(\"Model warm-up complete.\")\n",
    "\n",
    "#     def save_segments_to_wav(self, segments):\n",
    "#         combined_segments = np.concatenate(segments)\n",
    "#         filename = f\"output_{self.counter}.wav\"\n",
    "#         sf.write(filename, combined_segments, self.RATE, \"FLOAT\")\n",
    "#         print(f\"Saved combined segments to {filename}\")\n",
    "#         self.saving_counter += 1\n",
    "\n",
    "#     def predict(self, segments):\n",
    "#         sequence = np.concatenate(segments)\n",
    "#         spectrogram = self.spectrogram_from_audio_data(sequence)\n",
    "#         data_batch = np.vstack((self.batch_placeholder, spectrogram[np.newaxis, :, :]))\n",
    "#         prediction = self._model.predict(data_batch, verbose=0)\n",
    "#         prediction = prediction[-1][0]\n",
    "#         prediction = np.round(prediction, 2)\n",
    "#         if prediction > 0.81:\n",
    "#             print(\"\\nHi sir!\\n\")\n",
    "#         else:\n",
    "#             print(f\"Listening...........{prediction}%\")\n",
    "            \n",
    "#         print(\"Waiting\")\n",
    "#         time.sleep(3)\n",
    "    \n",
    "#     def process_audio(self):\n",
    "#         while True:\n",
    "#             segments = self.queue.get()\n",
    "#             if segments is None:\n",
    "#                 break\n",
    "#             self.predict(segments)\n",
    "    \n",
    "#     def spectrogram_from_audio_data(self, sequence):\n",
    "#         return spectrogramFromAudioData(audio_data=sequence)\n",
    "\n",
    "#     def callback(self, in_data, frame_count, time_info, status):\n",
    "#         start_time = time.perf_counter()\n",
    "#         audio_segment = np.frombuffer(in_data, dtype=np.float32)\n",
    "#         self.audio_buffer.append(audio_segment)\n",
    "#         print(len(self.audio_buffer))\n",
    "#         if len(self.audio_buffer) == self.DURATION:\n",
    "#             # self.predict(self.audio_buffer)\n",
    "#             self.queue.put(list(self.audio_buffer))\n",
    "#             # self.save_segments_to_wav(self.audio_buffer)  # Uncomment if you want to save the segments\n",
    "#         print(time.perf_counter()-start_time)\n",
    "#         return (in_data, pyaudio.paContinue)\n",
    "\n",
    "#     def start_stream(self):\n",
    "#         p = pyaudio.PyAudio()\n",
    "#         stream = p.open(\n",
    "#             format=self.FORMAT,\n",
    "#             channels=self.CHANNELS,\n",
    "#             rate=self.RATE,\n",
    "#             input=True,\n",
    "#             frames_per_buffer=self.CHUNK,\n",
    "#             stream_callback=self.callback,\n",
    "#         )\n",
    "\n",
    "#         print(\"Recording...\")\n",
    "#         stream.start_stream()\n",
    "#         try:\n",
    "#             while stream.is_active():\n",
    "#                 time.sleep(1)\n",
    "#         except KeyboardInterrupt:\n",
    "#             print(\"Interrupted by user\")\n",
    "\n",
    "#         stream.stop_stream()\n",
    "#         stream.close()\n",
    "#         p.terminate()\n",
    "#         print(\"Recording stopped.\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     audio_processor = AudioProcessor(model_name=\"best_model.h5\")\n",
    "#     audio_processor.start_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from internal_methods import spectrogramFromAudioData\n",
    "import pygame\n",
    "import os\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape defined: (40, 173)\n",
      "Warming up the model...\n",
      "Model warm-up completed.\n",
      "Recording...\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.12\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.12\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.13\n",
      "\n",
      "Moshi moshi\n",
      "Saved combined segments to output_11.wav\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.12\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.16\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.12\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.10\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.10\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.13\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.12\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.13\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.18\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.12\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.12\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.14\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.14\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.19\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.16\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.15\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.13\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.13\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.17\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.16\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.10\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "LISTENING... | Prediction: 0.0 | Time Escalated: 0.11\n",
      "\n",
      "Interrupted by user\n",
      "Recording stopped.\n"
     ]
    }
   ],
   "source": [
    "class AudioProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_shape: tuple | None = None,\n",
    "        model_path: str = \"model.keras\",\n",
    "        wake_response_audio: str = \"beep.wav\",\n",
    "        wake_response_message: str = \"Moshi moshi\",\n",
    "        use_model_warm_up=True,\n",
    "        batch_size=32,\n",
    "        rate=44100,\n",
    "        channels=1,\n",
    "        format=pyaudio.paFloat32,\n",
    "        duration=2,\n",
    "        save_dir=\"wake_record\",\n",
    "        verbose: int | bool = 1,\n",
    "    ):\n",
    "        # Audio related variables\n",
    "        self.RATE: int = rate\n",
    "        self.CHANNELS: int = channels\n",
    "        self.FORMAT = format\n",
    "        self.SAMPLE_WIDTH = pyaudio.PyAudio().get_sample_size(format)\n",
    "        self.DURATION: int = duration\n",
    "        self.CHUNK: int = self.RATE  # 1 second chunks\n",
    "        self.audio_buffer = deque(maxlen=self.DURATION)\n",
    "\n",
    "        # Add a single chunk to the buffer, so that from the beginning of recording there will be already 2 chunks\n",
    "        self.buffer_placeholder: np.ndarray = np.zeros(shape=(self.RATE,))\n",
    "        self.audio_buffer.append(self.buffer_placeholder)\n",
    "\n",
    "        # Saving related variables\n",
    "        self.save_dir: str = save_dir\n",
    "        self._saving_counter: int = len(os.listdir(self.save_dir))\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Model related variables\n",
    "        self.sample_shape = sample_shape\n",
    "        if self.sample_shape is None:\n",
    "            self.sample_shape = self._define_sample_shape()\n",
    "        self.batch_size: int = batch_size\n",
    "        self.batch_placeholder: np.ndarray = np.zeros(\n",
    "            shape=(self.batch_size - 1,) + self.sample_shape\n",
    "        )  # Batch placeholder, So if the model is trained on batch of 32, it creates a shape of 31 samples and during prediction adds a single sample to the batch,\n",
    "        # thus mathing the batch size\n",
    "\n",
    "        self.model_path: str = model_path\n",
    "        self._model = self.load_model()\n",
    "\n",
    "        # Play beep sound everytime the model recognized a wake word\n",
    "        self.wake_response_audio: str = wake_response_audio\n",
    "        self.wake_response_message: str = wake_response_message\n",
    "        self.mixer = pygame.mixer\n",
    "        self.mixer.init()\n",
    "        self.wake_response_sound = self.mixer.Sound(self.wake_response_audio)\n",
    "        self.wake_response_channel = self.mixer.Channel(0)\n",
    "\n",
    "        if use_model_warm_up:\n",
    "            self.warm_up_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        return tf.keras.models.load_model(self.model_path)\n",
    "\n",
    "    def log(self, *args, **kwargs):\n",
    "        if self.verbose:\n",
    "            print(*args, **kwargs)\n",
    "\n",
    "    def warm_up_model(self, warm_up_cycles: int = 5):\n",
    "        self.log(\"Warming up the model...\")\n",
    "\n",
    "        dummy_input = np.zeros(\n",
    "            shape=(self.batch_size,) + self.sample_shape\n",
    "        )  # Replace with appropriate shape\n",
    "        for _ in range(warm_up_cycles):\n",
    "            self._model.predict(dummy_input, verbose=0)\n",
    "\n",
    "        self.log(\"Model warm-up completed.\")\n",
    "\n",
    "    def _define_sample_shape(self):\n",
    "        buffer_shape = self.DURATION * self.RATE\n",
    "        dummy_sequence = np.ones(shape=buffer_shape)\n",
    "        spectrogram_sample = self._spectrogram_from_audio_data(dummy_sequence)\n",
    "        sample_shape = spectrogram_sample.shape\n",
    "        self.log(f\"Sample shape defined: {sample_shape}\")\n",
    "        return sample_shape\n",
    "\n",
    "    def _save_segments_to_wav(self, segments):\n",
    "        combined_segments = np.concatenate(segments)\n",
    "        filename = f\"output_{self._saving_counter}.wav\"\n",
    "        save_path = os.path.join(self.save_dir, filename)\n",
    "        sf.write(save_path, combined_segments, self.RATE, \"FLOAT\")\n",
    "        self.log(f\"Saved combined segments to {filename}\")\n",
    "        self._saving_counter += 1\n",
    "\n",
    "    def _spectrogram_from_audio_data(self, sequence):\n",
    "        return spectrogramFromAudioData(audio_data=sequence)\n",
    "\n",
    "    def _predict(self, segments):\n",
    "        sequence = np.concatenate(segments)\n",
    "        spectrogram = self._spectrogram_from_audio_data(sequence)\n",
    "        data_batch = np.vstack((self.batch_placeholder, spectrogram[np.newaxis, :, :]))\n",
    "        prediction = self._model.predict(data_batch, verbose=0)\n",
    "        prediction = prediction[-1][0]\n",
    "        prediction = np.round(prediction, 2)\n",
    "        return prediction\n",
    "\n",
    "    def callback(self, in_data, frame_count, time_info, status):\n",
    "        start_time = time.perf_counter()\n",
    "        audio_segment = np.frombuffer(in_data, dtype=np.float32)\n",
    "        self.audio_buffer.append(audio_segment)\n",
    "\n",
    "        prediction = self._predict(self.audio_buffer)\n",
    "        if prediction > 0.8:\n",
    "\n",
    "            self.wake_response_channel.play(\n",
    "                self.wake_response_sound\n",
    "            )  # Play the beep sound on the channel\n",
    "\n",
    "            isFinished = False\n",
    "            while (\n",
    "                self.wake_response_channel.get_busy()\n",
    "            ):  # Wait until sound playback is complete\n",
    "                if not isFinished:\n",
    "                    self.log(self.wake_response_message)\n",
    "                    self._save_segments_to_wav(\n",
    "                        self.audio_buffer\n",
    "                    )  # Uncomment if you want to save the segments\n",
    "                    isFinished = True\n",
    "\n",
    "        else:\n",
    "            escalated_time = time.perf_counter() - start_time\n",
    "            self.log(\n",
    "                f\"LISTENING... | Prediction: {prediction} | Time Escalated: {escalated_time:.2f}\\n\"\n",
    "            )\n",
    "            if escalated_time > self.DURATION:\n",
    "                print(\n",
    "                    f\"WARNING: callback function took {escalated_time:.2f} seconds, which is longer than the chunk duration of 1 second.\\n\"\n",
    "                )\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "\n",
    "    def start_stream(self):\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(\n",
    "            format=self.FORMAT,\n",
    "            channels=self.CHANNELS,\n",
    "            rate=self.RATE,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.CHUNK,\n",
    "            stream_callback=self.callback,\n",
    "        )\n",
    "\n",
    "        print(\"Recording...\")\n",
    "        stream.start_stream()\n",
    "\n",
    "        try:\n",
    "            while stream.is_active():\n",
    "                time.sleep(1)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted by user\")\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "        print(\"Recording stopped.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    audio_processor = AudioProcessor(\n",
    "        model_path=\"best_model.h5\",\n",
    "    )\n",
    "    audio_processor.start_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
